# ANMOL DUDANI

## Contact Information

- Address: E-117, Bank Colony, Murlipura Jaipur, 302039
- Email: jaeckanaquth@gmail.com

## Education

- M.Tech. Vellore Institute of Technology, Vellore (CGPA – 8.67/10) June 2020
- B.Tech., Mody University, Lakshmangarh (CGPA – 6.27/10) June 2017

## Professional Experience

### Data Engineer, Drishya AI Labs (September 2020 – Present)

- An IT company dealing with creating Oil and Gas AI with an employee strength of 40.
- Driving growth and innovation for the company with 2 core products -- Brains and Artisan. Brains is an AI product that finds intelligence from data while Artisan is an AI product that finds intelligence from images.
- Coordinating the adoption of standardization of policies and resources to prevent fluctuations or anomalies in the infrastructure of the company and predict the growth of the company and estimate for a new project.
- Initiating and managing digital platforms for the company and good architecture review by endorsing best practices and enforcing policies and security regulations by supplementing tools to aid and guide developers.
- Streamlining the maintenance, testing, and designing of infrastructure resources in the company; Reviewing and remodeling the company’s existing budget and technology.

#### Achievements

- Initiated and created an automated billing system for the AWS platform that allowed to see the cost spent on every resource by name as well as the project it is dedicated to for smoother operations.
- Created a pipeline for real-time data consumption and display in conjunction with the AWS team, for the company to use batch data to model our AI but also use real-time data providing alarms, anomalies, and other real-time changes.
- Initiated a process where cloud architects are directed to build secure, high-performing, resilient, and efficient infrastructure for a variety of applications in conjunction with the AWS team which led to getting $5000 in AWS credits.
- Implemented AWS Single Sign-On (AWS SSO) where you create or connect, your workforce identities in AWS once and manage access centrally across your AWS organization, managing access just to AWS accounts or cloud applications.
- Reduced the hassle of passwords and account numbers and helped when we moved to a multi-account strategy making it secure as it is integrated by 2-way verification which we set up on our Gmail.
- Implemented IAM that deals with the access control to assets inside AWS where AWS IAM provides permanent access to an AWS account to provide access to code repositories on GitHub as well as Users before the introduction of SSO.
- Studied virtual private networks that address the challenge of resources being able to remain secure and inside company space which can access the internet and communicate with the internet as well as each other.
- Created a workspace set up for individuals working from home where all the work done by an employee is done inside the workspace under company control.
- Assisted in easy monitoring of the employees without the restriction of physical location, access to their work status as well as the security of data that stays in the company network and improved work efficiency by 20%.

### Projects

#### Implementation of Automatic Numberplate Recognition

- Built a customized version of ANPR coding using the numberplate recognition function of the original object detector and using a custom script for Indian truck numberplates which are not native to the project.
- Developed a socket programming for use on all Reliance locations.
- Improved the speed for detection under the R&D.

#### Implementation of the full Architecture of ELK

- Put the full architecture of Elasticsearch, Logstash and Kibana under R&D and implemented it for SAP.
- Created dataflow for logs and metrics ingestion and created dashboards in Kibana for monitoring and visualizing the data.
- Built a custom pipeline in Logstash for parsing and enriching the logs before indexing into Elasticsearch.
- Implemented Elasticsearch cluster with multiple nodes and created replicas for high availability and fault tolerance.
- Configured Elasticsearch indices with proper mappings and settings to optimize the search and aggregation performance.
- Used Elasticsearch query DSL for searching and filtering the data and created custom aggregations to generate reports.
- Built custom visualizations in Kibana using the Vega visualization language to create charts and graphs for various metrics.
- Created alerts and notifications in Elasticsearch Watcher to monitor critical events and notify the concerned stakeholders.

#### Data Analysis and Visualization using Python

- Analyzed a dataset of online retail transactions using Python and various data analysis libraries such as pandas, NumPy, and Matplotlib.
- Cleaned and preprocessed the data by handling missing values, data type conversions, and normalization.
- Conducted exploratory data analysis (EDA) to understand the patterns and trends in the data and used statistical methods to test the hypotheses.
- Created interactive visualizations using the Plotly library to display the insights obtained from EDA.
- Built a predictive model using the scikit-learn library to forecast the sales for the next quarter and evaluated the model's performance using various metrics.

#### Implementation of Automatic Number Plate Recognition (ANPR)

- Developed a customized version of ANPR system using the number plate recognition function of the original object detector and a custom script for Indian truck number plates which are not native to the project.
- Implemented the ANPR system using a deep learning framework called YOLOv4 and trained the model on a large dataset of license plate images.
- Optimized the model's performance by tuning the hyperparameters and using data augmentation techniques.
- Integrated the ANPR system with a socket programming for use in all Reliance locations.
- Improved the speed of detection and recognition under R&D.

#### Certifications

- IBM Applied AI (10/2020)
- Diploma in Japanese Language (09/2019)
- Python for Data Science and AI (09/2020)

## Skills

- Programming Languages: Python, SQL, Java, C++
- Big Data Technologies: Elasticsearch, Logstash, Kibana, Hadoop, Spark
- Machine Learning Frameworks: Scikit-learn, TensorFlow, PyTorch, Keras
- Cloud Platforms: AWS, Google Cloud, Microsoft Azure
- Databases: MySQL, PostgreSQL, MongoDB
- Operating Systems: Linux, Windows
- Tools: Git, Jupyter Notebook, Docker, Jenkins, Ansible

<<<<<<< Updated upstream:readme.md
- Reading about new technologies and advancements in the field of AI and ML.
- Playing video games and chess in my free time.
- Volunteering at local NGOs to provide education to underprivileged children.
=======
## Personal Projects

#### Sentiment Analysis of Movie Reviews

- Built a machine learning model to classify the sentiment of movie reviews as positive, negative, or neutral using the IMDB dataset.
- Preprocessed the text data by removing stop words, stemming, and tokenizing the words.
- Trained the model using a deep learning framework called Keras with a recurrent neural network (RNN) architecture.
- Achieved an accuracy of 85% on the test set and visualized the results using confusion matrix and classification report.

#### Automated Stock Trading System

- Developed a system for automated trading of stocks using Python and Alpaca API.
- Integrated the system with real-time stock data using web scraping techniques and Alpaca API.
- Built a predictive model using machine learning to forecast the future prices of stocks.
- Used the model's predictions to buy and sell stocks automatically with proper risk management techniques.
- Achieved an average return of 10% per month and reduced the risk of loss using stop-loss and take-profit orders.

## Interests

- Machine Learning, Deep Learning, Natural Language Processing
- Data Science, Data Analysis
>>>>>>> Stashed changes:resume.md
